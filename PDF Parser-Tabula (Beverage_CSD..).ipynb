{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula as tb\n",
    "import re\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify the PDF File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_FILE = 'Beverage_CSD (GTC)_2DR - Narrow Short.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the bounding box to extract the regions:-**\n",
    "`Measured in number of Points on the page of PDF File`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bounding_box():\n",
    "    fc = 28.28 # conversion factor\n",
    "    box = [2,8,20,28] # It is in cm. Defined Intuitively. \n",
    "    for i in range(0, len(box)):\n",
    "        box[i] *= fc\n",
    "    return box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JSON Map will be created from here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_map(page_col_df,final_df):\n",
    "    \n",
    "    #Reset the index of the DataFrame, and use the default one instead. If the DataFrame has a MultiIndex, this method can remove one or more levels.\n",
    "    page_col_df.reset_index(drop=True, inplace=True)\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "    #Concatenate pandas objects along a particular axis with optional set logic along the other axe.{0/’index’, 1/’columns’}, default 0\n",
    "    final_df_pagewise = pd.concat([page_col_df, final_df], axis=1)\n",
    "    final_df_pagewise\n",
    "    \n",
    "    \n",
    "    y = final_df_pagewise[final_df_pagewise.apply(lambda r: r.str.contains('DOOR', case=False).any(), axis=1)]\n",
    "    page_door_record_dict = {}\n",
    "    door_record_dict = {}\n",
    "    page_num_prev = ''\n",
    "    for i in range(len(y)):\n",
    "        page_num = 'page_'+str(y.iloc[i][y.columns[0]])\n",
    "        door_num = str(y.iloc[i][y.columns[1]])\n",
    "        door_num_width = ''\n",
    "        door_num_depth = ''\n",
    "        \n",
    "        \n",
    "        for j in range(y.shape[1]):\n",
    "            cell_val = str(y.iloc[i][y.columns[j]])\n",
    "            if re.search('Width:'+'\\s*([a-zA-Z0-9_.-.\\']*)',cell_val):\n",
    "                door_num_width = re.search('Width:'+'\\s*([a-zA-Z0-9_.-.\\']*)',cell_val).group().split(':')[1]\n",
    "            if re.search('Depth:'+'\\s*([a-zA-Z0-9_.-.\\']*)\\s*([a-zA-Z0-9_.-.\\']*)',cell_val) :\n",
    "                door_num_depth = re.search('Depth:'+'\\s*([a-zA-Z0-9_.-.\\']*)\\s*([a-zA-Z0-9_.-.\\']*)',cell_val).group().split(': ')[1]\n",
    "        \n",
    "        if page_num_prev != page_num:\n",
    "            door_record_dict = {}\n",
    "            page_num_prev = page_num\n",
    "        door_record_dict[door_num] =  {\"Width\":door_num_width, \"Depth\":door_num_depth}\n",
    "        page_door_record_dict[page_num] = door_record_dict\n",
    "    print(page_door_record_dict)\n",
    "    return page_door_record_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PreProcessing of Raw data Extracted from PDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def pre_processing(final_df):\n",
    "    final_df = final_df[final_df[final_df.columns[0]].notna()] # Remove the rows where LOCMCLANE is NaN.\n",
    "    final_df = final_df.fillna(method='ffill')\n",
    "\n",
    "    for i in range(len(final_df)):\n",
    "        loc_mclane = final_df.iloc[i][final_df.columns[0]] #final_df[final_df.columns[0]].values[i] #\n",
    "        loc_mclane_prev = ''\n",
    "        # only choose those mclane which contains only integer.\n",
    "        if loc_mclane.isdecimal():\n",
    "            loc_mclane_prev = final_df.iloc[i-1][final_df.columns[0]]\n",
    "            loc_mclane_new = loc_mclane + ' ' + loc_mclane_prev\n",
    "            final_df.loc[i,final_df.columns[0]] = loc_mclane_new\n",
    "            final_df_1 = final_df.drop([final_df.index[i]])\n",
    "            final_df_1 = final_df_1.loc[final_df_1['LOC MCLANE'].str.contains(\"DOOR|\\d+\", case=False)]\n",
    "    return final_df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add Door Number in the DataFrame Extracted after Cleaning the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_door_number(final_df_1):\n",
    "    \n",
    "    door_re = re.compile(r'DOOR')\n",
    "    door = []\n",
    "    door_num = ''\n",
    "    door_row = []\n",
    "    for i in range(len(final_df_1)):\n",
    "        x = final_df_1.iloc[i][final_df_1.columns[0]]\n",
    "        if door_re.search(x):\n",
    "            door_num = x.split()[1]\n",
    "            door_row.append(i)\n",
    "        door.append(door_num)\n",
    "    result = pd.DataFrame(door,columns=['DOOR'])\n",
    "#     print(door_row)\n",
    "#     print(door)\n",
    "    return result,door_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Final DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(result,final_df_1,door_row):\n",
    "    \n",
    "    result.reset_index(drop=True, inplace=True)\n",
    "    final_df_1.reset_index(drop=True, inplace=True)\n",
    "    final = pd.concat([result, final_df_1], axis=1)\n",
    "    final = final.drop(final.index[door_row])\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract Raw Data From PDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data from page: 3\n",
      "Extracting Data from page: 3\n",
      "Extracting Data from page: 4\n",
      "Extracting Data from page: 4\n",
      "Extracting Data from page: 5\n",
      "Extracting Data from page: 5\n",
      "Extracting Data from page: 6\n",
      "Extracting Data from page: 6\n"
     ]
    }
   ],
   "source": [
    "box = create_bounding_box()\n",
    "required_column = ['LOC MCLANE', 'Desc_A', 'UNIT UPC', 'PACK', 'DESCRIPTION','Size', 'UOM', 'FACINGS']\n",
    "final_df = []\n",
    "page_list = []\n",
    "with pdfplumber.open(PDF_FILE) as pdf:\n",
    "        pages = pdf.pages\n",
    "        for i,page in enumerate(pages):\n",
    "            \n",
    "            page_number = [i+1] \n",
    "            df = []\n",
    "            \n",
    "            if page_number[0]>2:\n",
    "                print(\"Extracting Data from page:\",page_number[0])\n",
    "                tl = tb.read_pdf(PDF_FILE, pages=page_number,area=[box],output_format=\"dataframe\", stream=True)\n",
    "                df = tl[0]\n",
    "                df = df[required_column]              \n",
    "                final_df.append(df)\n",
    "        \n",
    "                page_list =page_list + (page_number*len(df))                \n",
    "\n",
    "final_df = pd.concat(final_df)\n",
    "# final_df.to_csv(\"demo.csv\", index=False)\n",
    "page_col_df = pd.DataFrame(page_list,columns=['Page'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create JSON File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_3': {'DOOR 1/1': {'Width': '', 'Depth': ''}, 'DOOR 1/2': {'Width': '', 'Depth': ''}, 'DOOR 1/3': {'Width': '', 'Depth': ''}, 'DOOR 1/4': {'Width': '', 'Depth': ''}, 'DOOR 1/5': {'Width': '', 'Depth': ''}}, 'page_4': {'DOOR 1/6': {'Width': '', 'Depth': ''}}, 'page_5': {'DOOR 2/1': {'Width': '', 'Depth': ''}, 'DOOR 2/2': {'Width': '', 'Depth': ''}, 'DOOR 2/3': {'Width': '', 'Depth': ''}, 'DOOR 2/4': {'Width': '', 'Depth': ''}}, 'page_6': {'DOOR 2/5': {'Width': '', 'Depth': ''}, 'DOOR 2/6': {'Width': '', 'Depth': ''}, 'DOOR DISCO': {'Width': '', 'Depth': ''}, 'DOOR NEW': {'Width': '', 'Depth': ''}}}\n",
      "[INFO]: Successfully created JSON File!!\n",
      "{'page_3': {'DOOR 1/1': {'Width': '', 'Depth': ''}, 'DOOR 1/2': {'Width': '', 'Depth': ''}, 'DOOR 1/3': {'Width': '', 'Depth': ''}, 'DOOR 1/4': {'Width': '', 'Depth': ''}, 'DOOR 1/5': {'Width': '', 'Depth': ''}}, 'page_4': {'DOOR 1/6': {'Width': '', 'Depth': ''}}, 'page_5': {'DOOR 2/1': {'Width': '', 'Depth': ''}, 'DOOR 2/2': {'Width': '', 'Depth': ''}, 'DOOR 2/3': {'Width': '', 'Depth': ''}, 'DOOR 2/4': {'Width': '', 'Depth': ''}}, 'page_6': {'DOOR 2/5': {'Width': '', 'Depth': ''}, 'DOOR 2/6': {'Width': '', 'Depth': ''}, 'DOOR DISCO': {'Width': '', 'Depth': ''}, 'DOOR NEW': {'Width': '', 'Depth': ''}}}\n",
      "[INFO]: Successfully created JSON File!!\n"
     ]
    }
   ],
   "source": [
    "page_door_record_dict = create_json_map(page_col_df,final_df)\n",
    "dict_to_json = json.dumps(page_door_record_dict)\n",
    "print(\"[INFO]: Successfully created JSON File!!\")\n",
    "\n",
    "json_file = PDF_FILE.split('.')[0] + \".shelves.json\"\n",
    "with open(json_file, \"w\") as f:\n",
    "    f.write(dict_to_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get The DataFrame Extracted from the PDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_1 = pre_processing(final_df)\n",
    "result,door_row = add_door_number(final_df_1)\n",
    "final = get_final_df(result,final_df_1,door_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export into CSV or TSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = PDF_FILE.split('.')[0] + '.table.csv'\n",
    "tsv_file = PDF_FILE.split('.')[0] + '.table.tsv'\n",
    "final.to_csv(tsv_file,sep='\\t', index=False)\n",
    "final.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
